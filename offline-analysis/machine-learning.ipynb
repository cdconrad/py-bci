{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting P300 \n",
    "Blah.\n",
    "\n",
    "This notebook and related process is based on the work of Aaron Newman and Colin Conrad. It follows the MIT lisence though, so feel free to use it and change it however you would like -- just make sure you credit this work! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the necessary libraries\n",
    "We will need to import a large number of libraries (such as MNE and scikit-learn) as well as datasets. If you are not familiar with Python, don't worry, we will work through these together soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#note: using the Python 2.7 kernel\n",
    "import numpy as np\n",
    "import matplotlib, mne\n",
    "from mne.io.reference import set_eeg_reference\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from mne import io, compute_raw_covariance, pick_types, read_events, Epochs\n",
    "from mne.decoding import Vectorizer, PSDEstimator\n",
    "from mne.viz import tight_layout\n",
    "from mne.decoding import CSP \n",
    "from mne.time_frequency import psd_multitaper\n",
    "from mne.filter import filter_data\n",
    "from mne.preprocessing import Xdawn\n",
    "\n",
    "data_path = '/eeg_recordings/p300-speller'\n",
    "\n",
    "subjects = ['01','02','03','04','05','06']\n",
    "\n",
    "datasets = []\n",
    "\n",
    "mne.set_log_level('error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate epochs with no filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ./01/eeg_recordings\\p300-speller-01.fdt\n",
      "Reading 0 ... 138995  =      0.000 ...   271.475 secs...\n",
      "Used Annotations descriptions: ['1', '2']\n",
      "720 events found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-fd5d131c06ac>:9: DeprecationWarning: stim_channel (default True in 0.17) will change to False in 0.18 and be removed in 0.19, set it to False in 0.17 to avoid this warning\n",
      "  preload=True)\n",
      "<ipython-input-23-fd5d131c06ac>:9: RuntimeWarning: The following EEG sensors did not have a position specified in the selected montage: [u'HEOG', u'VEOG']. Their position has been left untouched.\n",
      "  preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event IDs: [1 2]\n",
      "720 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "Loading data for 720 events and 155 original time points ...\n",
      "0 bad epochs dropped\n",
      "Reading ./02/eeg_recordings\\p300-speller-02.fdt\n",
      "Reading 0 ... 140055  =      0.000 ...   273.545 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-fd5d131c06ac>:9: DeprecationWarning: stim_channel (default True in 0.17) will change to False in 0.18 and be removed in 0.19, set it to False in 0.17 to avoid this warning\n",
      "  preload=True)\n",
      "<ipython-input-23-fd5d131c06ac>:9: RuntimeWarning: The following EEG sensors did not have a position specified in the selected montage: [u'HEOG', u'VEOG']. Their position has been left untouched.\n",
      "  preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['1', '2']\n",
      "720 events found\n",
      "Event IDs: [1 2]\n",
      "720 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "Loading data for 720 events and 155 original time points ...\n",
      "0 bad epochs dropped\n",
      "Reading ./03/eeg_recordings\\p300-speller-03.fdt\n",
      "Reading 0 ... 138895  =      0.000 ...   271.279 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-fd5d131c06ac>:9: DeprecationWarning: stim_channel (default True in 0.17) will change to False in 0.18 and be removed in 0.19, set it to False in 0.17 to avoid this warning\n",
      "  preload=True)\n",
      "<ipython-input-23-fd5d131c06ac>:9: RuntimeWarning: The following EEG sensors did not have a position specified in the selected montage: [u'HEOG', u'VEOG']. Their position has been left untouched.\n",
      "  preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['1', '2']\n",
      "720 events found\n",
      "Event IDs: [1 2]\n",
      "720 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "Loading data for 720 events and 155 original time points ...\n",
      "0 bad epochs dropped\n",
      "Reading ./04/eeg_recordings\\p300-speller-04.fdt\n",
      "Reading 0 ... 138555  =      0.000 ...   270.615 secs...\n",
      "Used Annotations descriptions: ['1', '2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-fd5d131c06ac>:9: DeprecationWarning: stim_channel (default True in 0.17) will change to False in 0.18 and be removed in 0.19, set it to False in 0.17 to avoid this warning\n",
      "  preload=True)\n",
      "<ipython-input-23-fd5d131c06ac>:9: RuntimeWarning: The following EEG sensors did not have a position specified in the selected montage: [u'HEOG', u'VEOG']. Their position has been left untouched.\n",
      "  preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720 events found\n",
      "Event IDs: [1 2]\n",
      "720 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "Loading data for 720 events and 155 original time points ...\n",
      "0 bad epochs dropped\n",
      "Reading ./05/eeg_recordings\\p300-speller-05.fdt\n",
      "Reading 0 ... 139255  =      0.000 ...   271.982 secs...\n",
      "Used Annotations descriptions: ['1', '2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-fd5d131c06ac>:9: DeprecationWarning: stim_channel (default True in 0.17) will change to False in 0.18 and be removed in 0.19, set it to False in 0.17 to avoid this warning\n",
      "  preload=True)\n",
      "<ipython-input-23-fd5d131c06ac>:9: RuntimeWarning: The following EEG sensors did not have a position specified in the selected montage: [u'HEOG', u'VEOG']. Their position has been left untouched.\n",
      "  preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720 events found\n",
      "Event IDs: [1 2]\n",
      "720 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "Loading data for 720 events and 155 original time points ...\n",
      "0 bad epochs dropped\n",
      "Reading ./06/eeg_recordings\\p300-speller-06.fdt\n",
      "Reading 0 ... 150919  =      0.000 ...   294.764 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-fd5d131c06ac>:9: DeprecationWarning: stim_channel (default True in 0.17) will change to False in 0.18 and be removed in 0.19, set it to False in 0.17 to avoid this warning\n",
      "  preload=True)\n",
      "<ipython-input-23-fd5d131c06ac>:9: RuntimeWarning: The following EEG sensors did not have a position specified in the selected montage: [u'HEOG', u'VEOG']. Their position has been left untouched.\n",
      "  preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['1', '2']\n",
      "720 events found\n",
      "Event IDs: [1 2]\n",
      "720 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "Loading data for 720 events and 155 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "datasets = []\n",
    "\n",
    "for s in subjects:\n",
    "    raw_fname = './' + s + '/eeg_recordings/p300-speller-'+ s + '.set' #epochs filename \n",
    "    raw = mne.io.read_raw_eeglab(raw_fname, \n",
    "                          #eog=['VEOG', 'HEOG']\n",
    "                          event_id={'Nontarget':1, 'Target':2}, \n",
    "                          montage='standard_1020',\n",
    "                          preload=True) \n",
    "    events = mne.find_events(raw) \n",
    "    picks_eeg = mne.pick_types(raw.info, eeg=True, eog=True,\n",
    "                           stim=False, exclude=[]) \n",
    "    epochs = mne.Epochs(raw, events, {'Nontarget':1, 'Target':2}, 0, 0.3, proj=False,\n",
    "                    picks=picks_eeg, baseline=None, preload=True)\n",
    "    datasets.append(epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Epochs  |   720 events (all good), 0 - 0.300781 sec, baseline off, ~29.0 MB, data loaded,\n",
       "  'Nontarget': 620\n",
       "  'Target': 100>,\n",
       " <Epochs  |   720 events (all good), 0 - 0.300781 sec, baseline off, ~29.0 MB, data loaded,\n",
       "  'Nontarget': 604\n",
       "  'Target': 116>,\n",
       " <Epochs  |   720 events (all good), 0 - 0.300781 sec, baseline off, ~29.0 MB, data loaded,\n",
       "  'Nontarget': 623\n",
       "  'Target': 97>,\n",
       " <Epochs  |   720 events (all good), 0 - 0.300781 sec, baseline off, ~29.0 MB, data loaded,\n",
       "  'Nontarget': 623\n",
       "  'Target': 97>,\n",
       " <Epochs  |   720 events (all good), 0 - 0.300781 sec, baseline off, ~29.0 MB, data loaded,\n",
       "  'Nontarget': 607\n",
       "  'Target': 113>,\n",
       " <Epochs  |   720 events (all good), 0 - 0.300781 sec, baseline off, ~29.0 MB, data loaded,\n",
       "  'Nontarget': 604\n",
       "  'Target': 116>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now classify\n",
    "Based on https://www.martinos.org/mne/stable/auto_examples/decoding/plot_decoding_xdawn_eeg.html#sphx-glr-auto-examples-decoding-plot-decoding-xdawn-eeg-py\n",
    "\n",
    "This classifier will just go to majority class. We need to implement a subsampler first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Singular value decomposition (SVD) LDA Accuracy for Subject 06: 0.5958333333333333\n",
      "\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "Subject 06Nontarget       0.86      0.63      0.73       620\n",
      "   Subject 06Target       0.14      0.37      0.20       100\n",
      "\n",
      "          micro avg       0.60      0.60      0.60       720\n",
      "          macro avg       0.50      0.50      0.47       720\n",
      "       weighted avg       0.76      0.60      0.66       720\n",
      "\n",
      "[[392 228]\n",
      " [ 63  37]]\n",
      "Singular value decomposition (SVD) LDA Accuracy for Subject 06: 0.7236111111111111\n",
      "\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "Subject 06Nontarget       0.83      0.84      0.84       604\n",
      "   Subject 06Target       0.12      0.11      0.12       116\n",
      "\n",
      "          micro avg       0.72      0.72      0.72       720\n",
      "          macro avg       0.48      0.48      0.48       720\n",
      "       weighted avg       0.72      0.72      0.72       720\n",
      "\n",
      "[[508  96]\n",
      " [103  13]]\n",
      "Singular value decomposition (SVD) LDA Accuracy for Subject 06: 0.7986111111111112\n",
      "\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "Subject 06Nontarget       0.87      0.90      0.89       623\n",
      "   Subject 06Target       0.18      0.14      0.16        97\n",
      "\n",
      "          micro avg       0.80      0.80      0.80       720\n",
      "          macro avg       0.53      0.52      0.52       720\n",
      "       weighted avg       0.78      0.80      0.79       720\n",
      "\n",
      "[[561  62]\n",
      " [ 83  14]]\n",
      "Singular value decomposition (SVD) LDA Accuracy for Subject 06: 0.7791666666666667\n",
      "\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "Subject 06Nontarget       0.86      0.89      0.87       623\n",
      "   Subject 06Target       0.11      0.09      0.10        97\n",
      "\n",
      "          micro avg       0.78      0.78      0.78       720\n",
      "          macro avg       0.49      0.49      0.49       720\n",
      "       weighted avg       0.76      0.78      0.77       720\n",
      "\n",
      "[[552  71]\n",
      " [ 88   9]]\n",
      "Singular value decomposition (SVD) LDA Accuracy for Subject 06: 0.7458333333333333\n",
      "\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "Subject 06Nontarget       0.84      0.86      0.85       607\n",
      "   Subject 06Target       0.16      0.14      0.15       113\n",
      "\n",
      "          micro avg       0.75      0.75      0.75       720\n",
      "          macro avg       0.50      0.50      0.50       720\n",
      "       weighted avg       0.74      0.75      0.74       720\n",
      "\n",
      "[[521  86]\n",
      " [ 97  16]]\n",
      "Singular value decomposition (SVD) LDA Accuracy for Subject 06: 0.7652777777777777\n",
      "\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "Subject 06Nontarget       0.84      0.89      0.86       604\n",
      "   Subject 06Target       0.19      0.14      0.16       116\n",
      "\n",
      "          micro avg       0.77      0.77      0.77       720\n",
      "          macro avg       0.52      0.51      0.51       720\n",
      "       weighted avg       0.74      0.77      0.75       720\n",
      "\n",
      "[[535  69]\n",
      " [100  16]]\n",
      "***************************************************\n",
      "* Average Accuracy Among Subjects: 0.734722222222 *\n",
      "***************************************************\n"
     ]
    }
   ],
   "source": [
    "lda_raw_acc = []\n",
    "for d in datasets:\n",
    "    \n",
    "    clf = make_pipeline(Vectorizer(),\n",
    "                    MinMaxScaler(),\n",
    "                    LinearDiscriminantAnalysis(n_components=1, priors=None, shrinkage=None, solver='svd', store_covariance=False, tol=0.0001))\n",
    "\n",
    "    labels = d.events[:, -1]\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42) #split into the n-folds for n-fold cross validation\n",
    "\n",
    "    preds = np.empty(len(labels))\n",
    "    \n",
    "    for train, test in cv.split(d, labels):\n",
    "        clf.fit(d[train], labels[train])\n",
    "        preds[test] = clf.predict(d[test])\n",
    "    \n",
    "    name = s[0:2]\n",
    "    \n",
    "    target_names = ['Subject ' + name + 'Nontarget', 'Subject ' + name+'Target']\n",
    "    report = classification_report(labels, preds, target_names=target_names)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    matrix = confusion_matrix(labels, preds)\n",
    "    \n",
    "    print \"Singular value decomposition (SVD) LDA Accuracy for Subject \" + name + \": \" + str(acc) + \"\\n\"\n",
    "    print report #use this for a detailed report including precision, recall and f-measure\n",
    "    print matrix\n",
    "    lda_raw_acc.append(float(acc))\n",
    "    \n",
    "avg_acc = sum(lda_raw_acc)/len(lda_raw_acc)\n",
    "\n",
    "print \"***************************************************\"\n",
    "print \"* Average Accuracy Among Subjects: \" + str(avg_acc) + \" *\"\n",
    "print \"***************************************************\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Singular value decomposition (SVD) LDA Accuracy for Subject 02: 0.8388888888888889\n",
      "\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "Subject 02Nontarget       0.84      1.00      0.91       604\n",
      "   Subject 02Target       0.00      0.00      0.00       116\n",
      "\n",
      "          micro avg       0.84      0.84      0.84       720\n",
      "          macro avg       0.42      0.50      0.46       720\n",
      "       weighted avg       0.70      0.84      0.77       720\n",
      "\n",
      "[[604   0]\n",
      " [116   0]]\n"
     ]
    }
   ],
   "source": [
    "s = '02'\n",
    "\n",
    "raw_fname = './' + s + '/eeg_recordings/p300-speller-'+ s + '.set' #epochs filename \n",
    "\n",
    "raw = mne.io.read_raw_eeglab(raw_fname,\n",
    "                             eog=['VEOG', 'HEOG'],\n",
    "                             event_id={'Nontarget':1, 'Target':2}, \n",
    "                             montage='standard_1020',\n",
    "                             preload=True) \n",
    "\n",
    "raw.filter(0.1, 40, \n",
    "           l_trans_bandwidth = 'auto', \n",
    "           h_trans_bandwidth = 'auto', \n",
    "           filter_length= 'auto', \n",
    "           method='fft', \n",
    "           n_jobs = 4)  \n",
    "\n",
    "events = mne.find_events(raw) \n",
    "\n",
    "picks_eeg = mne.pick_types(raw.info, eeg=True, eog=False, stim=False, exclude=[]) \n",
    "\n",
    "epochs = mne.Epochs(raw, events, {'Nontarget':1, 'Target':2}, 0, 0.3, proj=False,\n",
    "                picks=picks_eeg, baseline=None, preload=True)\n",
    "\n",
    "d = epochs\n",
    "\n",
    "clf = make_pipeline(Xdawn(n_components=2),\n",
    "                    Vectorizer(),\n",
    "                    MinMaxScaler(),\n",
    "                    LogisticRegression(penalty='l1', solver='liblinear',\n",
    "                                       multi_class='auto'))\n",
    "labels = d.events[:, -1]\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42) #split into the n-folds for n-fold cross validation\n",
    "\n",
    "preds = np.empty(len(labels))\n",
    "\n",
    "for train, test in cv.split(d, labels):\n",
    "    clf.fit(d[train], labels[train])\n",
    "    preds[test] = clf.predict(d[test])\n",
    "\n",
    "name = s[0:2]\n",
    "\n",
    "target_names = ['Subject ' + name + 'Nontarget', 'Subject ' + name+'Target']\n",
    "report = classification_report(labels, preds, target_names=target_names)\n",
    "acc = accuracy_score(labels, preds)\n",
    "matrix = confusion_matrix(labels, preds)\n",
    "\n",
    "print \"Singular value decomposition (SVD) LDA Accuracy for Subject \" + name + \": \" + str(acc) + \"\\n\"\n",
    "print report #use this for a detailed report including precision, recall and f-measure\n",
    "print matrix\n",
    "lda_raw_acc.append(float(acc))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
